{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet ChatBot Team4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ouzy012/IA_Project_team4/blob/master/Projet_ChatBot_Team4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx3lKjkFvvJY",
        "colab_type": "text"
      },
      "source": [
        "This code come from \n",
        "https://medium.com/analytics-vidhya/building-a-simple-chatbot-in-python-using-nltk-7c8c8215ac6e\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BccYSw2ulA26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk \n",
        "import numpy as np \n",
        "import random \n",
        "import string # pour traiter les chaînes python standard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IySnVhUyB4sX",
        "colab_type": "text"
      },
      "source": [
        "Nous lisons le fichier coronavirus.txt et convertirons l'ensemble du chatbot en une liste de phrases et une liste de mots pour un prétraitement ultérieur.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_upQW2Jywjxw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "68cc02ae-d7d2-4752-8977-750027326aee"
      },
      "source": [
        "# Connecting Google Drive Data Files to Google Colab Notebook.\n",
        "# Load the Google Drive helper and mount the drive.\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization. Click the link and provide the required information.\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5GKxCUPAh8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0a13b8e2-7678-44bb-c4db-3c6c416bf47f"
      },
      "source": [
        "f=open('/content/drive/My Drive/Projet/coronavirus.txt','r',errors = 'ignore')\n",
        "raw=f.read()\n",
        "raw=raw.lower()# converts to lowercase\n",
        "nltk.download('punkt') # first-time use only\n",
        "nltk.download('wordnet') # first-time use only\n",
        "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
        "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSlaAFQ4CQjM",
        "colab_type": "text"
      },
      "source": [
        "Nous allons maintenant définir une fonction appelée LemTokens qui prendra en entrée les jetons et retournera les jetons normalisés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj_AIsVFA3ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3OM0g2_CX6Z",
        "colab_type": "text"
      },
      "source": [
        "Ensuite, nous allons définir une fonction pour un message d'accueil par le bot, c'est-à-dire que si l'entrée d'un utilisateur est un message d'accueil, le bot doit renvoyer une réponse de salutation.ELIZA utilise un simple mot clé correspondant pour les salutations. Nous utiliserons ici le même concept."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHEl341kBBnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def greeting(sentence):\n",
        " \n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONQaTel8CoWI",
        "colab_type": "text"
      },
      "source": [
        "Pour générer une réponse de notre bot aux questions d'entrée, le concept de similitude des documents sera utilisé. Nous commençons donc par importer les modules nécessaires."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB8bbjkqBJ38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3shPbRtBQog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzod02G1C6Aw",
        "colab_type": "text"
      },
      "source": [
        "Il sera utilisé pour trouver la similitude entre les mots saisis par l'utilisateur et les mots du chatbot. Il s'agit de l'implémentation la plus simple possible d'un chatbot.\n",
        "Nous définissons une réponse de fonction qui recherche dans l'énoncé de l'utilisateur un ou plusieurs mots clés connus et renvoie l'une des réponses possibles. S'il ne trouve pas l'entrée correspondant à l'un des mots clés, il renvoie une réponse: «Je suis désolé! Je ne te comprends pas »"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggw0uY2HBXtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sent_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGz4V2rdC90f",
        "colab_type": "text"
      },
      "source": [
        "Enfin, nous alimenterons les lignes que nous voulons que notre bot dise tout en commençant et en terminant une conversation en fonction de l'entrée de l'utilisateur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmrrs1Q0BgPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "b37e1557-4a49-4239-bd73-5ce43f6d136b"
      },
      "source": [
        "flag=True\n",
        "print(\"ROBO: My name is Robo of Team4. I will answer your queries about Coronavirus. If you want to exit, type Bye!\")\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            print(\"ROBO: You are welcome..\")\n",
        "        else:\n",
        "            if(greeting(user_response)!=None):\n",
        "                print(\"ROBO: \"+greeting(user_response))\n",
        "            else:\n",
        "                print(\"ROBO: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"ROBO: Bye! take care..\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROBO: My name is Robo of Team4. I will answer your queries about Coronavirus. If you want to exit, type Bye!\n",
            "coronavirus\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ROBO: [61][62]\n",
            "\n",
            "genus: alphacoronavirus;[58] type species: alphacoronavirus 1 (tgev)\n",
            "species: alphacoronavirus 1, human coronavirus 229e, human coronavirus nl63, miniopterus bat coronavirus 1, miniopterus bat coronavirus hku8, porcine epidemic diarrhea virus, rhinolophus bat coronavirus hku2, scotophilus bat coronavirus 512\n",
            "genus betacoronavirus;[59] type species: murine coronavirus (mhv)\n",
            "species: betacoronavirus 1 (bovine coronavirus, human coronavirus oc43), hedgehog coronavirus 1, human coronavirus hku1, middle east respiratory syndrome-related coronavirus, murine coronavirus, pipistrellus bat coronavirus hku5, rousettus bat coronavirus hku9, severe acute respiratory syndrome-related coronavirus (sars-cov, sars-cov-2), tylonycteris bat coronavirus hku4\n",
            "genus gammacoronavirus;[16] type species: avian coronavirus (ibv)\n",
            "species: avian coronavirus, beluga whale coronavirus sw1\n",
            "genus deltacoronavirus; type species: bulbul coronavirus hku11\n",
            "species: bulbul coronavirus hku11, porcine coronavirus hku15\n",
            "origin\n",
            "\n",
            "origins of human coronaviruses with possible intermediate hosts\n",
            "the most recent common ancestor (mrca) of all coronaviruses is estimated to have existed as recently as 8000 bce, although some models place the common ancestor as far back as 55 million years or more, implying long term coevolution with bat and avian species.\n",
            "thank you\n",
            "ROBO: You are welcome..\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}